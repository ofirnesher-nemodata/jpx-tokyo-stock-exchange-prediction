{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# IMPORTS"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [],
   "source": [
    "# !pip install lightgbm\n",
    "# !pip install pandas_ta\n",
    "# !pip install pandas_ta --no-index --find-links=file:///kaggle/input/pandas-ta/"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from lightgbm import LGBMRegressor\n",
    "import pandas_ta as ta"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CONSTANTS"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [],
   "source": [
    "# TODO: make total calculation\n",
    "NUMBER_OF_STABLE_STOCKS = 370\n",
    "NUMBER_OF_DAILY_CHOSEN_STOCKS = 15\n",
    "DAYS_PERIODS = [10, 21, 63]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# FUNCTIONS"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [],
   "source": [
    "def get_stocks_traded_every_day(stock_prices_df):\n",
    "    \"\"\"Return stocks that are traded in every trading day in data and remove others\"\"\"\n",
    "    traded_stock_per_date = stock_prices_df['Date'].value_counts()\n",
    "    stocks_by_descending_trade_count = stock_prices_df['SecuritiesCode'].value_counts()\n",
    "    return stocks_by_descending_trade_count[stocks_by_descending_trade_count == len(traded_stock_per_date)].index.values\n",
    "\n",
    "\n",
    "def adjust_prices(df):\n",
    "    def calculate_adjusted(df):\n",
    "        \"\"\"apply AdjustmentFactor on columns\"\"\"\n",
    "        new = df.sort_index(ascending=False)\n",
    "        split_coef = new['AdjustmentFactor'].shift(1).fillna(1).cumprod()\n",
    "        new['adj_open'] = new['Open'] / split_coef\n",
    "        new['adj_close'] = new['Close'] / split_coef\n",
    "        new['adj_volume'] = split_coef * new['Volume']\n",
    "        return new.sort_index(ascending=True)\n",
    "\n",
    "    df = df.groupby('SecuritiesCode').apply(calculate_adjusted).reset_index(drop=True)\n",
    "    df.set_index('Date', inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "get_daily_change_in_price = lambda df: df.groupby('SecuritiesCode')['adj_close'].apply(lambda x: x.diff() / x)\n",
    "\n",
    "get_gap_from_market = lambda df: df['daily_change'] - df['market_change_mean']\n",
    "\n",
    "\n",
    "def get_features_for_prediction(df):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        df (pd.DataFrame)  : pd.DataFrame include stock_price\n",
    "        code (int)  : A local code for a listed company\n",
    "    Returns:\n",
    "        feats DataFrame (pd.DataFrame)\n",
    "    \"\"\"\n",
    "    result = []\n",
    "\n",
    "    for code in df['SecuritiesCode'].unique():\n",
    "        feats = df.loc[df['SecuritiesCode'] == code, ['SecuritiesCode', 'Target', 'adj_close', 'adj_volume']].copy()\n",
    "\n",
    "        for period in DAYS_PERIODS:\n",
    "            feats[f'return_{period}_days'] = feats['adj_close'].pct_change(period)\n",
    "            feats[f'volume_{period}_days'] = feats['adj_volume'].pct_change(period)\n",
    "            feats[f'ema_{period}_days'] = ta.ema(feats['adj_close'], length=period + 1)\n",
    "\n",
    "        # filling data for nan and inf\n",
    "        feats['adj_volume'] = feats['adj_volume'].fillna(0)\n",
    "        feats = feats.replace([np.inf, -np.inf], 0)\n",
    "        result.append(feats)\n",
    "\n",
    "    return pd.concat(result)\n",
    "\n",
    "\n",
    "def random_split_of_list_into_halves(l: list) -> [list, list]:\n",
    "    random.shuffle(l)\n",
    "    return l[:int(len(l) / 2)], l[int(len(l) / 2):]\n",
    "\n",
    "\n",
    "def set_rank(df):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        df (pd.DataFrame): including predict column\n",
    "    Returns:\n",
    "        df (pd.DataFrame): df with rank\n",
    "    \"\"\"\n",
    "    # set 'Rank' starting from 0\n",
    "    df.loc[:, 'Rank'] = np.arange(len(df))\n",
    "    return df\n",
    "\n",
    "\n",
    "def calc_spread_return_sharpe(df: pd.DataFrame, portfolio_size: int = 200, toprank_weight_ratio: float = 2) -> float:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        df (pd.DataFrame): predicted results\n",
    "        portfolio_size (int): # of equities to buy/sell\n",
    "        toprank_weight_ratio (float): the relative weight of the most highly ranked stock compared to the least.\n",
    "    Returns:\n",
    "        (float): sharpe ratio\n",
    "    \"\"\"\n",
    "\n",
    "    def _calc_spread_return_per_day(df, portfolio_size, toprank_weight_ratio):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            df (pd.DataFrame): predicted results\n",
    "            portfolio_size (int): # of equities to buy/sell\n",
    "            toprank_weight_ratio (float): the relative weight of the most highly ranked stock compared to the least.\n",
    "        Returns:\n",
    "            (float): spread return\n",
    "        \"\"\"\n",
    "        assert df['Rank'].min() == 0\n",
    "        assert df['Rank'].max() == len(df['Rank']) - 1\n",
    "        weights = np.linspace(start=toprank_weight_ratio, stop=1, num=portfolio_size)\n",
    "        purchase = (df.sort_values(by='Rank')['Target'][:portfolio_size] * weights).sum() / weights.mean()\n",
    "        short = (df.sort_values(by='Rank', ascending=False)['Target'][:portfolio_size] * weights).sum() / weights.mean()\n",
    "        return purchase - short\n",
    "\n",
    "    buf = df.groupby('Date').apply(_calc_spread_return_per_day, portfolio_size, toprank_weight_ratio)\n",
    "    sharpe_ratio = buf.mean() / buf.std()\n",
    "\n",
    "    return sharpe_ratio"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# PROCESS DATA"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [],
   "source": [
    "train_stock_prices = pd.read_csv(\n",
    "    os.path.join('../input/jpx-tokyo-stock-exchange-prediction/train_files', 'stock_prices.csv'))\n",
    "supplemental_stock_prices = pd.read_csv(\n",
    "    os.path.join('../input/jpx-tokyo-stock-exchange-prediction/supplemental_files', 'stock_prices.csv'))\n",
    "\n",
    "# our training data and test data concatenated\n",
    "stock_prices = pd.concat([train_stock_prices, supplemental_stock_prices])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [],
   "source": [
    "delisted_stocks = stock_prices[stock_prices['SupervisionFlag'] == True]['SecuritiesCode'].values\n",
    "daily_traded_stocks = get_stocks_traded_every_day(stock_prices)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We now have 1845 stocks which have available information in every trading day and which are NOT delisted.\n",
      "These remaining stocks are the ones we are going to analyze and \"play\" with from now on.\n"
     ]
    }
   ],
   "source": [
    "# TODO: make set and subtract\n",
    "daily_traded_stocks = [x for x in daily_traded_stocks if (x not in delisted_stocks)]\n",
    "print(\n",
    "    f'We now have {len(daily_traded_stocks)} stocks which have available information in every trading day and which are NOT delisted.\\n'\n",
    "    'These remaining stocks are the ones we are going to analyze and \"play\" with from now on.')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [],
   "source": [
    "listed_stock_prices = stock_prices.loc[\n",
    "    stock_prices['SecuritiesCode'].isin(daily_traded_stocks), ['Date', 'SecuritiesCode', 'Open', 'Close', 'Volume',\n",
    "                                                               'AdjustmentFactor', 'Target']]\n",
    "\n",
    "# x daily-traded & listed stocks * 1202 trading days = y rows\n",
    "assert len(listed_stock_prices) == len(daily_traded_stocks) * len(stock_prices['Date'].unique())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [],
   "source": [
    "adjusted_prices_df = adjust_prices(listed_stock_prices)\n",
    "adjusted_prices_df = adjusted_prices_df.sort_values(['SecuritiesCode', 'Date'], ascending=[True, True])\n",
    "adjusted_prices_df['daily_change'] = get_daily_change_in_price(adjusted_prices_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [],
   "source": [
    "market_change_mean = adjusted_prices_df.groupby('Date')['daily_change'].mean()\n",
    "market_change_mean = market_change_mean.rename('market_change_mean')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [],
   "source": [
    "all_stocks_df = adjusted_prices_df.join(market_change_mean, on='Date')\n",
    "all_stocks_df['market_gap'] = get_gap_from_market(all_stocks_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [],
   "source": [
    "statistics_df = all_stocks_df.groupby(by='SecuritiesCode')['market_gap'].agg(['mean', 'median', 'std'])\n",
    "statistics_df['abs_mean'] = np.abs(statistics_df['mean'])\n",
    "statistics_df.sort_values(by=['abs_mean', 'std'], ascending=True, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    mean    median       std  abs_mean\n",
      "SecuritiesCode                                        \n",
      "6986           -0.000003 -0.000033  0.022512  0.000003\n",
      "6157           -0.000003 -0.000441  0.052177  0.000003\n",
      "6594            0.000005  0.000557  0.051656  0.000005\n",
      "4733           -0.000006  0.000843  0.054603  0.000006\n",
      "8714           -0.000010 -0.000675  0.022756  0.000010\n"
     ]
    },
    {
     "data": {
      "text/plain": "<AxesSubplot:>"
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAUG0lEQVR4nO3df6zd9X3f8edrdkOTeAQzllvL9mqvtZoBTqZw69F2mq7FOlgSxVQLmiPamBbJasbSdCJazCo1f0zWmKb9aJaRygpRiIhy59K0WKV0Re6u0FQcAmkSxxCKWxg1ULw2hOSmEcXsvT/ON9rx5Zh77j33nGvfz/MhXd3veX8/3+/389axXufr7/mec1NVSJLa8DdWewKSpMkx9CWpIYa+JDXE0Jekhhj6ktSQ9as9gcVcdtlltW3btrNq3/3ud3nzm9+8OhNaRS32bc/taLHvcfb86KOP/kVV/e2F9fM+9Ldt28YjjzxyVm1ubo6ZmZnVmdAqarFve25Hi32Ps+ck/3tQ3cs7ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUkPP+E7mj2HbgvlU57tO3v3tVjitJi/FMX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGrJo6Cf5dJLTSb4+YN1HklSSy/pqtyU5meSJJNf21a9Kcrxb9/EkWbk2JEnDGOZM/zPAdQuLSbYCPw0801e7HNgLXNFtc0eSdd3qTwL7gR3dz2v2KUkar0VDv6oeBL45YNV/Bv41UH21PcBsVb1cVU8BJ4FdSTYBF1fVQ1VVwGeB60edvCRpaZb1hWtJ3gs8W1VfXXCVZjNwrO/xqa72Sre8sH6u/e+n978CpqammJubO2v9/Pz8a2qD3LrzzKJjxmGYuS3HsH2vJfbcjhb7Xo2elxz6Sd4E/ArwTwatHlCr16kPVFWHgEMA09PTNTMzc9b6ubk5FtYGuWm1vmXzxpmx7HfYvtcSe25Hi32vRs/LOdP/EWA78P2z/C3Al5PsoncGv7Vv7Bbgua6+ZUBdkjRBS75ls6qOV9Vbq2pbVW2jF+jvrKo/B44Ae5NclGQ7vTdsH66q54HvJLm6u2vnA8C9K9eGJGkYw9yy+XngIeDHkpxKcvO5xlbVCeAw8Bjwe8AtVfVqt/qDwKfovbn7J8D9I85dkrREi17eqar3L7J+24LHB4GDA8Y9Aly5xPlJklaQn8iVpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGjLMH0b/dJLTSb7eV/sPSb6R5GtJfivJJX3rbktyMskTSa7tq1+V5Hi37uNJsuLdSJJe1zBn+p8BrltQewC4sqreDvwxcBtAksuBvcAV3TZ3JFnXbfNJYD+wo/tZuE9J0pgtGvpV9SDwzQW136+qM93DY8CWbnkPMFtVL1fVU8BJYFeSTcDFVfVQVRXwWeD6FepBkjSk9Suwj18A/nu3vJnei8D3nepqr3TLC+sDJdlP738FTE1NMTc3d9b6+fn519QGuXXnmUXHjMMwc1uOYfteS+y5HS32vRo9jxT6SX4FOAN87vulAcPqdeoDVdUh4BDA9PR0zczMnLV+bm6OhbVBbjpw36JjxuHpG2fGst9h+15L7LkdLfa9Gj0vO/ST7APeA1zTXbKB3hn81r5hW4DnuvqWAXVJ0gQt65bNJNcBHwXeW1V/1bfqCLA3yUVJttN7w/bhqnoe+E6Sq7u7dj4A3Dvi3CVJS7TomX6SzwMzwGVJTgEfo3e3zkXAA92dl8eq6her6kSSw8Bj9C773FJVr3a7+iC9O4HeCNzf/UiSJmjR0K+q9w8o3/k64w8CBwfUHwGuXNLsJEkryk/kSlJDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqyKKhn+TTSU4n+Xpf7dIkDyR5svu9sW/dbUlOJnkiybV99auSHO/Wfbz7A+mSpAka5kz/M8B1C2oHgKNVtQM42j0myeXAXuCKbps7kqzrtvkksB/Y0f0s3KckacwWDf2qehD45oLyHuCubvku4Pq++mxVvVxVTwEngV1JNgEXV9VDVVXAZ/u2kSRNyPplbjdVVc8DVNXzSd7a1TcDx/rGnepqr3TLC+sDJdlP738FTE1NMTc3d9b6+fn519QGuXXnmUXHjMMwc1uOYfteS+y5HS32vRo9Lzf0z2XQdfp6nfpAVXUIOAQwPT1dMzMzZ62fm5tjYW2Qmw7ct+iYcXj6xpmx7HfYvtcSe25Hi32vRs/LvXvnhe6SDd3v0139FLC1b9wW4LmuvmVAXZI0QcsN/SPAvm55H3BvX31vkouSbKf3hu3D3aWg7yS5urtr5wN920iSJmTRyztJPg/MAJclOQV8DLgdOJzkZuAZ4AaAqjqR5DDwGHAGuKWqXu129UF6dwK9Ebi/+5EkTdCioV9V7z/HqmvOMf4gcHBA/RHgyiXNTpK0ovxEriQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktSQkUI/yb9KciLJ15N8PskPJrk0yQNJnux+b+wbf1uSk0meSHLt6NOXJC3FskM/yWbgl4DpqroSWAfsBQ4AR6tqB3C0e0ySy7v1VwDXAXckWTfa9CVJSzHq5Z31wBuTrAfeBDwH7AHu6tbfBVzfLe8BZqvq5ap6CjgJ7Brx+JKkJUhVLX/j5MPAQeB7wO9X1Y1JvlVVl/SNebGqNib5BHCsqu7u6ncC91fVPQP2ux/YDzA1NXXV7OzsWevn5+fZsGHDovM7/uxLy+5tFDs3v2Us+x2277XEntvRYt/j7Hn37t2PVtX0wvr65e6wu1a/B9gOfAv4jSQ/+3qbDKgNfMWpqkPAIYDp6emamZk5a/3c3BwLa4PcdOC+RceMw9M3zoxlv8P2vZbYczta7Hs1eh7l8s4/Bp6qqv9TVa8AXwB+EnghySaA7vfpbvwpYGvf9lvoXQ6SJE3IKKH/DHB1kjclCXAN8DhwBNjXjdkH3NstHwH2JrkoyXZgB/DwCMeXJC3Rsi/vVNUXk9wDfBk4A/wRvUsyG4DDSW6m98JwQzf+RJLDwGPd+Fuq6tUR5y9JWoJlhz5AVX0M+NiC8sv0zvoHjT9I741fSdIq8BO5ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkNGCv0klyS5J8k3kjye5CeSXJrkgSRPdr839o2/LcnJJE8kuXb06UuSlmLUM/1fA36vqt4GvAN4HDgAHK2qHcDR7jFJLgf2AlcA1wF3JFk34vElSUuw7NBPcjHwj4A7Aarqr6vqW8Ae4K5u2F3A9d3yHmC2ql6uqqeAk8Cu5R5fkrR0qarlbZj8feAQ8Bi9s/xHgQ8Dz1bVJX3jXqyqjUk+ARyrqru7+p3A/VV1z4B97wf2A0xNTV01Ozt71vr5+Xk2bNiw6ByPP/vSsnob1c7NbxnLfoftey2x53a02Pc4e969e/ejVTW9sL5+hH2uB94JfKiqvpjk1+gu5ZxDBtQGvuJU1SF6LyhMT0/XzMzMWevn5uZYWBvkpgP3LTpmHJ6+cWYs+x2277XEntvRYt+r0fMo1/RPAaeq6ovd43vovQi8kGQTQPf7dN/4rX3bbwGeG+H4kqQlWnboV9WfA3+W5Me60jX0LvUcAfZ1tX3Avd3yEWBvkouSbAd2AA8v9/iSpKUb5fIOwIeAzyV5A/CnwM/TeyE5nORm4BngBoCqOpHkML0XhjPALVX16ojHlyQtwUihX1VfAV7zRgG9s/5B4w8CB0c5piRp+fxEriQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhowc+knWJfmjJL/TPb40yQNJnux+b+wbe1uSk0meSHLtqMeWJC3NSpzpfxh4vO/xAeBoVe0AjnaPSXI5sBe4ArgOuCPJuhU4viRpSCOFfpItwLuBT/WV9wB3dct3Adf31Wer6uWqego4Cewa5fiSpKVJVS1/4+Qe4N8BfxP4SFW9J8m3quqSvjEvVtXGJJ8AjlXV3V39TuD+qrpnwH73A/sBpqamrpqdnT1r/fz8PBs2bFh0fseffWnZvY1i5+a3jGW/w/a9lthzO1rse5w97969+9Gqml5YX7/cHSZ5D3C6qh5NMjPMJgNqA19xquoQcAhgenq6ZmbO3v3c3BwLa4PcdOC+Iaa18p6+cWYs+x2277XEntvRYt+r0fOyQx/4KeC9Sd4F/CBwcZK7gReSbKqq55NsAk53408BW/u23wI8N8LxJUlLtOxr+lV1W1Vtqapt9N6g/YOq+lngCLCvG7YPuLdbPgLsTXJRku3ADuDhZc9ckrRko5zpn8vtwOEkNwPPADcAVNWJJIeBx4AzwC1V9eoYji9JOocVCf2qmgPmuuW/BK45x7iDwMGVOKYkaen8RK4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUkGWHfpKtSf5nkseTnEjy4a5+aZIHkjzZ/d7Yt81tSU4meSLJtSvRgCRpeKOc6Z8Bbq2qvwdcDdyS5HLgAHC0qnYAR7vHdOv2AlcA1wF3JFk3yuQlSUuzfrkbVtXzwPPd8neSPA5sBvYAM92wu4A54KNdfbaqXgaeSnIS2AU8tNw5nK+2HbhvLPu9decZblpk30/f/u6xHFvS2pCqGn0nyTbgQeBK4JmquqRv3YtVtTHJJ4BjVXV3V78TuL+q7hmwv/3AfoCpqamrZmdnz1o/Pz/Phg0bFp3X8WdfWm5L56WpN8IL33v9MTs3v2Uyk5mQYZ/rtaTFnqHNvsfZ8+7dux+tqumF9WWf6X9fkg3AbwK/XFXfTnLOoQNqA19xquoQcAhgenq6ZmZmzlo/NzfHwtogi50VX2hu3XmG/3j89Z+yp2+cmcxkJmTY53otabFnaLPv1eh5pLt3kvwAvcD/XFV9oSu/kGRTt34TcLqrnwK29m2+BXhulONLkpZmlLt3AtwJPF5V/6lv1RFgX7e8D7i3r743yUVJtgM7gIeXe3xJ0tKNcnnnp4CfA44n+UpX+zfA7cDhJDcDzwA3AFTViSSHgcfo3flzS1W9OsLxJUlLNMrdO/+LwdfpAa45xzYHgYPLPaYkaTR+IleSGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhoy8rdsSqttXH+/YDH+7QJdiDzTl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpId6nv8Z4z7qk1+OZviQ1ZOKhn+S6JE8kOZnkwKSPL0ktm+jlnSTrgP8G/DRwCvhSkiNV9dgk56GVN67LSrfuPMNNq3TJSlqLJn2mvws4WVV/WlV/DcwCeyY8B0lq1qTfyN0M/Fnf41PAP1g4KMl+YH/3cD7JEwuGXAb8xVhmeB77pQb7Pp97zr8f267P257HrMW+x9nzDw8qTjr0M6BWrylUHQIOnXMnySNVNb2SE7sQtNi3Pbejxb5Xo+dJX945BWzte7wFeG7Cc5CkZk069L8E7EiyPckbgL3AkQnPQZKaNdHLO1V1Jsm/BP4HsA74dFWdWMauznnpZ41rsW97bkeLfU+851S95pK6JGmN8hO5ktQQQ1+SGnJeh/5iX9mQno9367+W5J2rMc+VNETPb0vyUJKXk3xkNeY4DkP0fWP3HH8tyR8mecdqzHMlDdHznq7fryR5JMk/XI15rqRhv4YlyY8neTXJ+yY5v3EZ4rmeSfJS91x/Jcmvjm0yVXVe/tB7o/dPgL8LvAH4KnD5gjHvAu6nd///1cAXV3veE+j5rcCPAweBj6z2nCfY908CG7vlf9rIc72B//++29uBb6z2vMfdc9+4PwB+F3jfas97Qs/1DPA7k5jP+XymP8xXNuwBPls9x4BLkmya9ERX0KI9V9XpqvoS8MpqTHBMhun7D6vqxe7hMXqf8biQDdPzfHWJALyZAR9kvMAM+zUsHwJ+Ezg9ycmN0Xn19TPnc+gP+sqGzcsYcyFZa/0Ma6l930zvf3gXsqF6TvIzSb4B3Af8woTmNi6L9pxkM/AzwK9PcF7jNuy/759I8tUk9ye5YlyTOZ9Df5ivbBjqax0uIGutn2EN3XeS3fRC/6NjndH4DfuVJL9VVW8Drgf+7bgnNWbD9PxfgI9W1avjn87EDNP3l4Efrqp3AP8V+O1xTeZ8Dv1hvrJhrX2tw1rrZ1hD9Z3k7cCngD1V9ZcTmtu4LOm5rqoHgR9Jctm4JzZGw/Q8DcwmeRp4H3BHkusnMrvxWbTvqvp2Vc13y78L/MC4nuvzOfSH+cqGI8AHurt4rgZeqqrnJz3RFdTq11Qs2neSvwN8Afi5qvrjVZjjShum5x9Nkm75nfTeBLyQX+wW7bmqtlfVtqraBtwD/Iuq+u2Jz3RlDfNc/1Dfc72LXjaP5bk+b/9Gbp3jKxuS/GK3/tfpvbv/LuAk8FfAz6/WfFfCMD0n+SHgEeBi4P8m+WV6dwJ8e7XmPaohn+tfBf4WvTM/gDN1AX8j45A9/zN6JzWvAN8D/nnfG7sXnCF7XnOG7Pt9wAeTnKH3XO8d13Pt1zBIUkPO58s7kqQVZuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhvw/XYidDi2sq38AAAAASUVORK5CYII=\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(statistics_df.head())\n",
    "statistics_df['std'].hist()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The stocks with std around 0 (+-) are those that behave LIKE THE MARKET.\n",
    "We want them to be part of our prediction because they are the least-noisy stocks.\n",
    "\n",
    "Also, get all non-stable stocks (\"extreme\" stocks):\n",
    "These are the stocks from which we want to get the ones which are better/worse than the market"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [],
   "source": [
    "stable_stocks_statistics_df = statistics_df[:NUMBER_OF_STABLE_STOCKS]\n",
    "extreme_stocks_statistics_df = statistics_df[NUMBER_OF_STABLE_STOCKS:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [],
   "source": [
    "stable_stocks_df = all_stocks_df[all_stocks_df['SecuritiesCode'].isin(stable_stocks_statistics_df.index)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\"Top\": the stocks which are usually \"better\" then the market in terms of daily_change (on average)\n",
    "\"Bottom\": the stocks which are usually \"worse\" then the market in terms of daily_change (on average)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1086 top_stocks and 389 bottom_stocks\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"There are {len(extreme_stocks_statistics_df[extreme_stocks_statistics_df['mean'] > 0])} top_stocks and {len(extreme_stocks_statistics_df[extreme_stocks_statistics_df['mean'] < 0])} bottom_stocks\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generate features:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [
    {
     "data": {
      "text/plain": "1845"
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(extreme_stocks_statistics_df.index)) + len(set(stable_stocks_statistics_df.index))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [],
   "source": [
    "extreme_stocks_df = all_stocks_df[all_stocks_df['SecuritiesCode'].isin(set(extreme_stocks_statistics_df.index))]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [],
   "source": [
    "extreme_stocks_features_df = get_features_for_prediction(extreme_stocks_df)\n",
    "extreme_stocks_features_df = extreme_stocks_features_df.sort_values(by=['SecuritiesCode', 'Date'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "outputs": [
    {
     "data": {
      "text/plain": "            SecuritiesCode    Target  adj_close  adj_volume  return_10_days  \\\nDate                                                                          \n2017-01-04            1301  0.000730     2742.0     31400.0             NaN   \n2017-01-05            1301  0.002920     2738.0     17900.0             NaN   \n2017-01-06            1301 -0.001092     2740.0     19900.0             NaN   \n2017-01-10            1301 -0.005100     2748.0     24200.0             NaN   \n2017-01-11            1301 -0.003295     2745.0      9300.0             NaN   \n...                    ...       ...        ...         ...             ...   \n2022-05-23            9997 -0.013783      664.0    177600.0       -0.073919   \n2022-05-24            9997  0.006211      653.0    191600.0       -0.081575   \n2022-05-25            9997  0.004630      644.0    233300.0       -0.083926   \n2022-05-26            9997  0.024578      648.0    116400.0       -0.048458   \n2022-05-27            9997  0.000000      651.0    141100.0       -0.080508   \n\n            volume_10_days  ema_10_days  return_21_days  volume_21_days  \\\nDate                                                                      \n2017-01-04             NaN          NaN             NaN             NaN   \n2017-01-05             NaN          NaN             NaN             NaN   \n2017-01-06             NaN          NaN             NaN             NaN   \n2017-01-10             NaN          NaN             NaN             NaN   \n2017-01-11             NaN          NaN             NaN             NaN   \n...                    ...          ...             ...             ...   \n2022-05-23        0.107923   674.880939       -0.086657        0.903537   \n2022-05-24       -0.341581   671.234115       -0.096819        1.551265   \n2022-05-25        0.054702   666.695096       -0.117808        1.007745   \n2022-05-26       -0.497843   663.579247       -0.102493       -0.337130   \n2022-05-27       -0.567576   661.482706       -0.098338        0.017304   \n\n            ema_21_days  return_63_days  volume_63_days  ema_63_days  \nDate                                                                  \n2017-01-04          NaN             NaN             NaN          NaN  \n2017-01-05          NaN             NaN             NaN          NaN  \n2017-01-06          NaN             NaN             NaN          NaN  \n2017-01-10          NaN             NaN             NaN          NaN  \n2017-01-11          NaN             NaN             NaN          NaN  \n...                 ...             ...             ...          ...  \n2022-05-23   690.978755       -0.103914       -0.001686   709.320477  \n2022-05-24   687.676255       -0.118758        0.515823   707.587539  \n2022-05-25   683.878320       -0.111724       -0.233070   705.631000  \n2022-05-26   680.758466       -0.119565       -0.339012   703.857738  \n2022-05-27   678.170773       -0.104539        0.212199   702.231346  \n\n[1942575 rows x 13 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SecuritiesCode</th>\n      <th>Target</th>\n      <th>adj_close</th>\n      <th>adj_volume</th>\n      <th>return_10_days</th>\n      <th>volume_10_days</th>\n      <th>ema_10_days</th>\n      <th>return_21_days</th>\n      <th>volume_21_days</th>\n      <th>ema_21_days</th>\n      <th>return_63_days</th>\n      <th>volume_63_days</th>\n      <th>ema_63_days</th>\n    </tr>\n    <tr>\n      <th>Date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2017-01-04</th>\n      <td>1301</td>\n      <td>0.000730</td>\n      <td>2742.0</td>\n      <td>31400.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2017-01-05</th>\n      <td>1301</td>\n      <td>0.002920</td>\n      <td>2738.0</td>\n      <td>17900.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2017-01-06</th>\n      <td>1301</td>\n      <td>-0.001092</td>\n      <td>2740.0</td>\n      <td>19900.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2017-01-10</th>\n      <td>1301</td>\n      <td>-0.005100</td>\n      <td>2748.0</td>\n      <td>24200.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2017-01-11</th>\n      <td>1301</td>\n      <td>-0.003295</td>\n      <td>2745.0</td>\n      <td>9300.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2022-05-23</th>\n      <td>9997</td>\n      <td>-0.013783</td>\n      <td>664.0</td>\n      <td>177600.0</td>\n      <td>-0.073919</td>\n      <td>0.107923</td>\n      <td>674.880939</td>\n      <td>-0.086657</td>\n      <td>0.903537</td>\n      <td>690.978755</td>\n      <td>-0.103914</td>\n      <td>-0.001686</td>\n      <td>709.320477</td>\n    </tr>\n    <tr>\n      <th>2022-05-24</th>\n      <td>9997</td>\n      <td>0.006211</td>\n      <td>653.0</td>\n      <td>191600.0</td>\n      <td>-0.081575</td>\n      <td>-0.341581</td>\n      <td>671.234115</td>\n      <td>-0.096819</td>\n      <td>1.551265</td>\n      <td>687.676255</td>\n      <td>-0.118758</td>\n      <td>0.515823</td>\n      <td>707.587539</td>\n    </tr>\n    <tr>\n      <th>2022-05-25</th>\n      <td>9997</td>\n      <td>0.004630</td>\n      <td>644.0</td>\n      <td>233300.0</td>\n      <td>-0.083926</td>\n      <td>0.054702</td>\n      <td>666.695096</td>\n      <td>-0.117808</td>\n      <td>1.007745</td>\n      <td>683.878320</td>\n      <td>-0.111724</td>\n      <td>-0.233070</td>\n      <td>705.631000</td>\n    </tr>\n    <tr>\n      <th>2022-05-26</th>\n      <td>9997</td>\n      <td>0.024578</td>\n      <td>648.0</td>\n      <td>116400.0</td>\n      <td>-0.048458</td>\n      <td>-0.497843</td>\n      <td>663.579247</td>\n      <td>-0.102493</td>\n      <td>-0.337130</td>\n      <td>680.758466</td>\n      <td>-0.119565</td>\n      <td>-0.339012</td>\n      <td>703.857738</td>\n    </tr>\n    <tr>\n      <th>2022-05-27</th>\n      <td>9997</td>\n      <td>0.000000</td>\n      <td>651.0</td>\n      <td>141100.0</td>\n      <td>-0.080508</td>\n      <td>-0.567576</td>\n      <td>661.482706</td>\n      <td>-0.098338</td>\n      <td>0.017304</td>\n      <td>678.170773</td>\n      <td>-0.104539</td>\n      <td>0.212199</td>\n      <td>702.231346</td>\n    </tr>\n  </tbody>\n</table>\n<p>1942575 rows × 13 columns</p>\n</div>"
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extreme_stocks_features_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# MODEL"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [],
   "source": [
    "LGBM_PARAMS = {\n",
    "    'seed': 42,\n",
    "    'n_jobs': -1,\n",
    "}\n",
    "\n",
    "FEATURE_COLUMNS = [\n",
    "    'return_10_days',\n",
    "    'volume_10_days',\n",
    "    'ema_10_days',\n",
    "    'return_21_days',\n",
    "    'volume_21_days',\n",
    "    'ema_21_days',\n",
    "    'return_63_days',\n",
    "    'volume_63_days',\n",
    "    'ema_63_days'\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [],
   "source": [
    "def get_features_and_label(df):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        df (pd.DataFrame): loaded price data with features\n",
    "    Returns:\n",
    "        train_X (pd.DataFrame): training data\n",
    "        train_y (pd.DataFrame): label for train_X\n",
    "        test_X (pd.DataFrame): test data\n",
    "        test_y (pd.DataFrame): label for test_X\n",
    "    \"\"\"\n",
    "    # split data into TRAIN and TEST\n",
    "    TRAIN_END = \"2021-12-03\"\n",
    "    # We put a week gap between TRAIN_END and TEST_START\n",
    "    # to avoid leakage of test data information from label\n",
    "    TEST_START = \"2021-12-06\"\n",
    "\n",
    "    # to store splited data\n",
    "    trains_X, tests_X = [], []\n",
    "    trains_y, tests_y = [], []\n",
    "\n",
    "    # generate feature one by one\n",
    "    for code in df['SecuritiesCode'].unique():\n",
    "        feats = df[df['SecuritiesCode'] == code].dropna().drop(columns='Target')\n",
    "        labels = df.loc[df['SecuritiesCode'] == code, ['SecuritiesCode', 'Target']].dropna()\n",
    "\n",
    "        if feats.shape[0] > 0 and labels.shape[0] > 0:\n",
    "            # align label and feature indexes\n",
    "            labels = labels.loc[labels.index.isin(feats.index)]\n",
    "            feats = feats.loc[feats.index.isin(labels.index)]\n",
    "\n",
    "            assert (labels.loc[:, 'SecuritiesCode'] == feats.loc[:, 'SecuritiesCode']).all()\n",
    "            labels = labels['Target']\n",
    "\n",
    "            # split data into TRAIN and TEST\n",
    "            _train_X = feats[:TRAIN_END]\n",
    "            _test_X = feats[TEST_START:]\n",
    "\n",
    "            _train_y = labels[:TRAIN_END]\n",
    "            _test_y = labels[TEST_START:]\n",
    "\n",
    "            assert len(_train_X) == len(_train_y)\n",
    "            assert len(_test_X) == len(_test_y)\n",
    "\n",
    "            # store features\n",
    "            trains_X.append(_train_X)\n",
    "            tests_X.append(_test_X)\n",
    "            # store labels\n",
    "            trains_y.append(_train_y)\n",
    "            tests_y.append(_test_y)\n",
    "\n",
    "    # combine features for each codes\n",
    "    train_X = pd.concat(trains_X)\n",
    "    test_X = pd.concat(tests_X)\n",
    "    # combine label for each codes\n",
    "    train_y = pd.concat(trains_y)\n",
    "    test_y = pd.concat(tests_y)\n",
    "\n",
    "    return train_X, train_y, test_X, test_y\n",
    "\n",
    "\n",
    "def get_daily_ranked_results(df: pd.DataFrame) -> [pd.DataFrame, pd.DataFrame]:\n",
    "    # generate feature/label\n",
    "    train_X, train_y, test_X, test_y = get_features_and_label(df)\n",
    "    # initialize model\n",
    "    pred_model = LGBMRegressor(**LGBM_PARAMS)\n",
    "    # train\n",
    "    pred_model.fit(train_X[FEATURE_COLUMNS].values, train_y)\n",
    "    # prepare result data\n",
    "    result = test_X[['SecuritiesCode']].copy()\n",
    "    # predict\n",
    "    result.loc[:, 'predict'] = pred_model.predict(test_X[FEATURE_COLUMNS])\n",
    "    # actual result\n",
    "    result.loc[:, 'Target'] = test_y.values\n",
    "    # sort results by date and ascending/descending \"predict\", depending on which group we want:\n",
    "    # the higher the \"predict\" the more likely to BUY the stock\n",
    "    # the lower the \"predict\" the more likely to SELL the stock\n",
    "    result = result.sort_values(['Date', 'predict'], ascending=[True, False])\n",
    "    # set_rank\n",
    "    ranked_results = result.groupby('Date').apply(set_rank)\n",
    "    # Drop unnecessary columns. Keep only those which are relevant for submission:\n",
    "    ranked_results_no_labels_df = ranked_results.drop(columns=['predict'])\n",
    "\n",
    "    group = ranked_results_no_labels_df.groupby('Date')\n",
    "    return [group.head(NUMBER_OF_DAILY_CHOSEN_STOCKS), group.tail(NUMBER_OF_DAILY_CHOSEN_STOCKS)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "outputs": [],
   "source": [
    "top_daily_chosen_stocks_df, bottom_daily_chosen_stocks_df = get_daily_ranked_results(extreme_stocks_features_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "outputs": [],
   "source": [
    "def get_final_ranks_df(top_df: pd.DataFrame, stable_stocks_df: pd.DataFrame,\n",
    "                       bottom_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    result_df = pd.DataFrame()\n",
    "    stable_stock_list = list(set(stable_stocks_df['SecuritiesCode']))\n",
    "\n",
    "    for d in top_df.index.unique():\n",
    "        first_half, second_half = random_split_of_list_into_halves(stable_stock_list)\n",
    "        result_df = pd.concat([result_df,\n",
    "                               top_df.loc[top_df.index == d, ['SecuritiesCode']],\n",
    "                               stable_stocks_df.loc[(stable_stocks_df.index == d) & (\n",
    "                                   stable_stocks_df['SecuritiesCode'].isin(\n",
    "                                       first_half)), ['SecuritiesCode']],\n",
    "                               stable_stocks_df.loc[(stable_stocks_df.index == d) & (\n",
    "                                   stable_stocks_df['SecuritiesCode'].isin(\n",
    "                                       second_half)), ['SecuritiesCode']],\n",
    "                               bottom_df.loc[bottom_df.index == d, ['SecuritiesCode']]])\n",
    "\n",
    "    result_df.index.name = 'Date'\n",
    "    return result_df\n",
    "\n",
    "\n",
    "final_ranks_df = get_final_ranks_df(top_daily_chosen_stocks_df, stable_stocks_df, bottom_daily_chosen_stocks_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## re-rank concatenated daily"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [
    {
     "data": {
      "text/plain": "             Date  SecuritiesCode  Rank\n0      2021-12-06            1821     0\n1      2021-12-06            8558     1\n2      2021-12-06            6310     2\n3      2021-12-06            2288     3\n4      2021-12-06            8061     4\n...           ...             ...   ...\n45995  2022-05-27            2002   395\n45996  2022-05-27            2475   396\n45997  2022-05-27            1885   397\n45998  2022-05-27            2395   398\n45999  2022-05-27            5726   399\n\n[46000 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>SecuritiesCode</th>\n      <th>Rank</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2021-12-06</td>\n      <td>1821</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2021-12-06</td>\n      <td>8558</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2021-12-06</td>\n      <td>6310</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2021-12-06</td>\n      <td>2288</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2021-12-06</td>\n      <td>8061</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>45995</th>\n      <td>2022-05-27</td>\n      <td>2002</td>\n      <td>395</td>\n    </tr>\n    <tr>\n      <th>45996</th>\n      <td>2022-05-27</td>\n      <td>2475</td>\n      <td>396</td>\n    </tr>\n    <tr>\n      <th>45997</th>\n      <td>2022-05-27</td>\n      <td>1885</td>\n      <td>397</td>\n    </tr>\n    <tr>\n      <th>45998</th>\n      <td>2022-05-27</td>\n      <td>2395</td>\n      <td>398</td>\n    </tr>\n    <tr>\n      <th>45999</th>\n      <td>2022-05-27</td>\n      <td>5726</td>\n      <td>399</td>\n    </tr>\n  </tbody>\n</table>\n<p>46000 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df = final_ranks_df.groupby('Date').apply(set_rank).reset_index(drop=False)\n",
    "submission_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [
    {
     "data": {
      "text/plain": "array([400], dtype=int64)"
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df.Date.value_counts().unique()  # 400 every day"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "outputs": [],
   "source": [
    "submission_df.to_csv('submission.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SUBMIT\n",
    "Will not work on local run!\n",
    "Must be run through Kaggle's Kernel - open a notebook there and copy this notebook\n",
    "\n",
    "You will get an error if you:\n",
    "- Use ranks that are below zero or greater than or equal to the number of stocks for a given date.\n",
    "- Submit any duplicated ranks.\n",
    "- Change the order of the rows."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "outputs": [],
   "source": [
    "def predict(df, prices, sample):\n",
    "    ff = df[df['Date'] == prices['Date'].iloc[0]]\n",
    "    ff = ff[ff['SecuritiesCode'].isin(df['SecuritiesCode'].unique())]\n",
    "    mp = ff.set_index('SecuritiesCode')['Rank']\n",
    "    sample = sample[sample['SecuritiesCode'].isin(ff['SecuritiesCode'].unique())].copy()\n",
    "    sample['Rank'] = sample.SecuritiesCode.map(mp)\n",
    "    sample = sample.sort_values(by='Rank')\n",
    "    sample = sample.reset_index(drop=True)\n",
    "    assert sample['Rank'].min() == 0\n",
    "    assert sample['Rank'].max() == 399\n",
    "\n",
    "    return sample"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "outputs": [],
   "source": [
    "# test_prices = pd.read_csv('../prices_1.csv')\n",
    "# sample_prediction = pd.read_csv('../sample_prediction_1.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'jpx_tokyo_market_prediction'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_21040/3904038219.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[1;32mimport\u001B[0m \u001B[0mjpx_tokyo_market_prediction\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0menv\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mjpx_tokyo_market_prediction\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmake_env\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# initialize the environment\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0miter_test\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0menv\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0miter_test\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# an iterator which loops over the test files\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'jpx_tokyo_market_prediction'"
     ]
    }
   ],
   "source": [
    "import jpx_tokyo_market_prediction\n",
    "\n",
    "env = jpx_tokyo_market_prediction.make_env()  # initialize the environment\n",
    "iter_test = env.iter_test()  # an iterator which loops over the test files"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for prices, _, _, _, _, sample_prediction in iter_test:\n",
    "    # prices is a single-day DataFrame with columns 'Date', 'SecuritiesCode', 'Open', 'Close', 'Volume'\n",
    "    # sample_prediction is a single-day DataFrame with columns 'Date', 'SecuritiesCode', 'Rank'\n",
    "    predict(submission_df, prices, sample_prediction)\n",
    "    env.predict(sample_prediction)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! head submission.csv"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}